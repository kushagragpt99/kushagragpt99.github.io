<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>data flow graphs | Kushagra Gupta</title>
    <link>/tags/data-flow-graphs/</link>
      <atom:link href="/tags/data-flow-graphs/index.xml" rel="self" type="application/rss+xml" />
    <description>data flow graphs</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Â© Kushagra Gupta 2020</copyright><lastBuildDate>Sat, 04 Jan 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/img/pom-card.png</url>
      <title>data flow graphs</title>
      <link>/tags/data-flow-graphs/</link>
    </image>
    
    <item>
      <title>Introduction to tensorflow</title>
      <link>/talk/2019-tensorflow/</link>
      <pubDate>Sat, 04 Jan 2020 00:00:00 +0000</pubDate>
      <guid>/talk/2019-tensorflow/</guid>
      <description>




  
  











&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;/talk/2019-tensorflow/tensors_flowing_hu0bd88d939c7ea5a767fc2ea7039b1f27_443056_2000x2000_fit_lanczos.gif&#34; &gt;


  &lt;img data-src=&#34;/talk/2019-tensorflow/tensors_flowing_hu0bd88d939c7ea5a767fc2ea7039b1f27_443056_2000x2000_fit_lanczos.gif&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;252&#34; height=&#34;448&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;This talk was part of Programming Club, IIT Kanpur&amp;rsquo;s talk on reinforcement learning. This talk was targeted for sophomores and junior undergraduates with some statistical background on Markov process and Monte Carlo. It covers the components of an RL model, namely policy, value function and agent&amp;rsquo;s representation of the environment. Next, it covers the basics of Markov reward process and the Bellman expectation equation, necessary to mathematically define the update procedure of the RL agent. This talk also covers the basic algorithms of training the RL agent, namely policy and value iteration. Towards the end, it touches upon the model-free methods of RL and explains the underlying mechanism behind model-free learning.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
