<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>All Talks &amp; Workshops | Kushagra Gupta</title>
    <link>https://kushagragpt99.github.io/talk/</link>
      <atom:link href="https://kushagragpt99.github.io/talk/index.xml" rel="self" type="application/rss+xml" />
    <description>All Talks &amp; Workshops</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Â© Kushagra Gupta 2020</copyright><lastBuildDate>Sat, 04 Jan 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://kushagragpt99.github.io/img/pom-card.png</url>
      <title>All Talks &amp; Workshops</title>
      <link>https://kushagragpt99.github.io/talk/</link>
    </image>
    
    <item>
      <title>Introduction to tensorflow</title>
      <link>https://kushagragpt99.github.io/talk/2019-tensorflow/</link>
      <pubDate>Sat, 04 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://kushagragpt99.github.io/talk/2019-tensorflow/</guid>
      <description>




  
  











&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://kushagragpt99.github.io/talk/2019-tensorflow/tensors_flowing_hu0bd88d939c7ea5a767fc2ea7039b1f27_443056_2000x2000_fit_lanczos.gif&#34; &gt;


  &lt;img data-src=&#34;https://kushagragpt99.github.io/talk/2019-tensorflow/tensors_flowing_hu0bd88d939c7ea5a767fc2ea7039b1f27_443056_2000x2000_fit_lanczos.gif&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;252&#34; height=&#34;448&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;This talk was part of Programming Club, IIT Kanpur&amp;rsquo;s talk on machine learning frameworks. This talk was targeted for sophomores and junior undergraduates with some background on deep learning. It explained dataflow graphs (which represent TensorFlow computations) and its basic terminologies and functions. Next, it covered basic implementation in TensorFlow through a toy problem on MNIST dataset, including the neural network and the dataflow graph for the problem. It also covered the installation procedure of the GPU and the CPU-only version.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introduction to Deep Learning</title>
      <link>https://kushagragpt99.github.io/talk/2019-basic_dl/</link>
      <pubDate>Sun, 15 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://kushagragpt99.github.io/talk/2019-basic_dl/</guid>
      <description>














&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;basic_ml.png&#34; &gt;


  &lt;img src=&#34;basic_ml.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;This talk was part of Programming Club, IIT Kanpur&amp;rsquo;s talk on introduction to deep learning. This talk was targeted for freshers and sophomores (both UG and PG) who are starting with machine learning. It covered topics like the most popular convex cost functions, activation functions and gradient descent, along with hands-on coding experience of these topics. It served as a medium of introducing deep learning to the campus community and as a starting step to explore more complex topics.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Reinforcement Learning</title>
      <link>https://kushagragpt99.github.io/talk/2019-rl/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://kushagragpt99.github.io/talk/2019-rl/</guid>
      <description>




  
  











&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://kushagragpt99.github.io/talk/2019-rl/RL_hu28e342dfb08d6419167a58ebb9883a60_21215_2000x2000_fit_lanczos_2.png&#34; &gt;


  &lt;img data-src=&#34;https://kushagragpt99.github.io/talk/2019-rl/RL_hu28e342dfb08d6419167a58ebb9883a60_21215_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;800&#34; height=&#34;382&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;This talk was part of Programming Club, IIT Kanpur&amp;rsquo;s talk on reinforcement learning (RL). It was targeted for sophomores and junior undergraduates with some statistical background on Markov process and Monte Carlo. It covered the components of an RL model, namely policy, value function and agent&amp;rsquo;s representation of the environment. Additionally, it covered the basics of Markov reward process and the Bellman expectation equation, necessary to define the update procedure of the RL agent mathematically. This talk also covered the basic algorithms of training the RL agent, namely policy and value iteration. Towards the end, it touched upon the model-free methods of RL and explained the underlying mechanism behind model-free learning.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
